{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T11:40:54.378624Z",
     "start_time": "2020-07-28T11:40:54.374636Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import MySQLdb\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Externel_Data_API.bus_weather_crawler import BusWeatherCrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T11:40:54.875535Z",
     "start_time": "2020-07-28T11:40:54.871563Z"
    }
   },
   "outputs": [],
   "source": [
    "line = '17'\n",
    "direction = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:01:40.353284Z",
     "start_time": "2020-07-28T05:01:40.104893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data base and Load weather\n",
    "cxn = MySQLdb.connect(user='user', password='nUT8+~nYRS/9-i$')\n",
    "cur = cxn.cursor()\n",
    "weather_DF = pd.read_csv(\"2018_daily_inserted.csv\", index_col=\"Unnamed: 0\")\n",
    "weather_DF.date = weather_DF.date.astype(\"datetime64[ns]\")\n",
    "weather_DF.time = weather_DF.time.apply(lambda x: datetime.datetime.strptime(x, \"%H:%M:%S\").time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T03:25:10.014090Z",
     "start_time": "2020-07-28T03:20:23.429646Z"
    }
   },
   "outputs": [],
   "source": [
    "def GetData(cur, line, direction):\n",
    "    # cur.execute('select * from busduck.leavetimes_01 LIMIT 0,10;')\n",
    "    query = \"\"\"\n",
    "    SELECT * FROM busduck.rt_leavetimes_db where TRIPID in \n",
    "    (SELECT TRIPID FROM busduck.rt_trips_db where LINEID=\"{}\" and DIRECTION = {});\n",
    "    \"\"\"\n",
    "    cur.execute(query.format(line, direction))\n",
    "    rows = cur.fetchall()\n",
    "    return    pd.DataFrame(rows, columns=[i[0] for i in cur.description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = GetData(cur, line, direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T03:44:56.694520Z",
     "start_time": "2020-07-28T03:44:56.579589Z"
    }
   },
   "outputs": [],
   "source": [
    "unused_cols = [\"DATASOURCE\", \"VEHICLEID\", \"PASSENGERS\", \"PASSENGERSIN\", \"PASSENGERSOUT\",\n",
    "              \"DISTANCE\", \"SUPPRESSED\", \"JUSTIFICATIONID\",\"LASTUPDATE\",\"NOTE\", \"PLANNEDTIME_ARR\", \"PLANNEDTIME_DEP\"]\n",
    "DF = DF.drop(unused_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T03:44:57.247555Z",
     "start_time": "2020-07-28T03:44:57.243565Z"
    }
   },
   "outputs": [],
   "source": [
    "def seconds_to_timedelta(x):\n",
    "    \"\"\"convert seconds to timedelta\"\"\"\n",
    "    return datetime.timedelta(seconds=x)\n",
    "\n",
    "def time_to_periods(x):\n",
    "    \"\"\"convert time to periods defined\"\"\"\n",
    "    if x.minute < 30:\n",
    "        m = 0\n",
    "    else:\n",
    "        m = 30\n",
    "    return datetime.time(x.hour,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:02:57.912831Z",
     "start_time": "2020-07-28T05:02:51.982653Z"
    }
   },
   "outputs": [],
   "source": [
    "DF[\"ACTUALTIME_ARR_DATETIME\"] = DF[\"DAYOFSERVICE\"] + DF[\"ACTUALTIME_ARR\"].apply(seconds_to_timedelta)\n",
    "DF[\"ACTUALTIME_DEP_DATETIME\"] = DF[\"DAYOFSERVICE\"] + DF[\"ACTUALTIME_DEP\"].apply(seconds_to_timedelta)\n",
    "DF[\"WEEK_DAY\"] = DF[\"DAYOFSERVICE\"].dt.dayofweek\n",
    "ts = pd.Series(1,index=DF[\"ACTUALTIME_ARR_DATETIME\"])\n",
    "DF[\"PERIOD\"] = DF[\"ACTUALTIME_ARR_DATETIME\"].apply(time_to_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:02:58.513222Z",
     "start_time": "2020-07-28T05:02:57.979611Z"
    }
   },
   "outputs": [],
   "source": [
    "DF_merged = pd.merge(DF, weather_DF, left_on=['DAYOFSERVICE','PERIOD'], \\\n",
    "         right_on=['date','time'], how='left').drop(['date','time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:03:06.502853Z",
     "start_time": "2020-07-28T05:02:58.575019Z"
    }
   },
   "outputs": [],
   "source": [
    "DF_merged['DWELLTIME'] = DF_merged[\"ACTUALTIME_DEP\"] - DF_merged[\"ACTUALTIME_ARR\"]\n",
    "DF_merged[\"STARTEND\"] = DF_merged.groupby(['DAYOFSERVICE','TRIPID'])['STOPPOINTID'].apply(lambda x:x.shift(1)+'_'+x)\n",
    "DF_merged['DIFFTIME'] = DF_merged.groupby(['DAYOFSERVICE','TRIPID'])['ACTUALTIME_ARR'].apply(lambda x:x.diff(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T11:41:11.621809Z",
     "start_time": "2020-07-28T11:41:11.616823Z"
    }
   },
   "outputs": [],
   "source": [
    "def Get_Distance(line, DF_merged):\n",
    "    crawler = BusWeatherCrawler()\n",
    "    START_END_dist = list(DF_merged[\"STARTEND\"].unique())\n",
    "    START_END_dist = [x for x in START_END_dist if str(x) != 'nan']\n",
    "    START_END_dist = pd.DataFrame(START_END_dist, columns=[\"STARTEND\"])\n",
    "    distances_l = []\n",
    "    for i in START_END_dist[\"STARTEND\"]:\n",
    "        l = i.split(\"_\")\n",
    "        distances_l.append(crawler.request_distance_api(l[0],l[1],line))\n",
    "    START_END_dist[\"DISTANCE\"] = distances_l\n",
    "    return START_END_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T04:17:05.765244Z",
     "start_time": "2020-07-28T04:05:04.794477Z"
    }
   },
   "outputs": [],
   "source": [
    "START_END_dist = Get_Distance(line, DF_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:03:07.201941Z",
     "start_time": "2020-07-28T05:03:06.570630Z"
    }
   },
   "outputs": [],
   "source": [
    "DF_merged = pd.merge(DF_merged, START_END_dist, on=['STARTEND'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:03:14.178800Z",
     "start_time": "2020-07-28T05:03:07.262777Z"
    }
   },
   "outputs": [],
   "source": [
    "t = DF_merged.groupby(['DAYOFSERVICE','TRIPID']).apply(lambda x:x[\"DIFFTIME\"] -x.shift(1)[\"DWELLTIME\"])\n",
    "# There is a bug from pandas 0.12, solution is:\n",
    "# reset twice the index\n",
    "t = t.reset_index(level=0, drop=True)\n",
    "t = t.reset_index(level=0, drop=True)\n",
    "DF_merged['RUNNINGTIME'] = t\n",
    "del(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:03:17.575227Z",
     "start_time": "2020-07-28T05:03:14.247094Z"
    }
   },
   "outputs": [],
   "source": [
    "t = DF_merged.groupby(['DAYOFSERVICE','TRIPID']).apply(lambda x:x[\"DISTANCE\"] / x[\"RUNNINGTIME\"])\n",
    "# There is a bug from pandas 0.12, solution is:\n",
    "# reset twice the index\n",
    "t = t.reset_index(level=0, drop=True)\n",
    "t = t.reset_index(level=0, drop=True)\n",
    "DF_merged[\"VELOCITY\"] = t\n",
    "del(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:05:38.207314Z",
     "start_time": "2020-07-28T05:05:38.199301Z"
    }
   },
   "outputs": [],
   "source": [
    "DF = DF_merged\n",
    "del DF_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:05:38.436657Z",
     "start_time": "2020-07-28T05:05:38.410727Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_datetype = [\"DAYOFSERVICE\",\"ACTUALTIME_ARR_DATETIME\",\"ACTUALTIME_DEP_DATETIME\"]\n",
    "for i in cols_to_datetype:\n",
    "    DF[i] = DF[i].astype('datetime64[ns]')\n",
    "    \n",
    "cols_to_cat = [\"TRIPID\",\"STOPPOINTID\", \"WEEK_DAY\",\"condition\"]#,\"PERIOD\"\n",
    "for i in cols_to_cat:\n",
    "    DF[i] = DF[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:17:57.076111Z",
     "start_time": "2020-07-28T05:17:56.614383Z"
    }
   },
   "outputs": [],
   "source": [
    "DF.PERIOD = DF.PERIOD.apply(lambda x: str(x)) # PERIOD to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:18:04.412025Z",
     "start_time": "2020-07-28T05:18:04.407990Z"
    }
   },
   "outputs": [],
   "source": [
    "def first_filter(x):\n",
    "    # not sure about the min DIFFTIME?\n",
    "    if x.DIFFTIME.min() > 7: # drop all routes with any wrong DIFFTIME\n",
    "        if ~np.isinf(x.VELOCITY).any(): # drop all routes with any wrong VELOCITY\n",
    "            if len(x) > 5: # drop all short routes with less than 5 stops\n",
    "                if x.RUNNINGTIME.min() > 0: #drop all routes with any wrong RUNNINGTIME\n",
    "#                     if x.PROGRNUMBER.reset_index(drop=True).equals(pd.Series(range(x.PROGRNUMBER.min(), x.PROGRNUMBER.max()+1))):\n",
    "                    # drop discontinuousness routes\n",
    "#                         return False\n",
    "#                     else:\n",
    "                    return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:18:12.633273Z",
     "start_time": "2020-07-28T05:18:05.150244Z"
    }
   },
   "outputs": [],
   "source": [
    "Grouped = DF.groupby(['DAYOFSERVICE','TRIPID'], observed=True)\n",
    "DF_filtered = Grouped.filter(first_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:08:37.378518Z",
     "start_time": "2020-07-28T05:08:37.374570Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(start, end, dow, period, line='17'):\n",
    "    start = '1310'\n",
    "    end = '1311'\n",
    "    start_end = start + '_' + end\n",
    "    DF_filtered[DF_filtered.eval(\"STARTEND == '{}'\".format(start_end))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:08:37.472309Z",
     "start_time": "2020-07-28T05:08:37.467311Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_every_two(start=1310, end=1311, dow=0, period = '12:00:00', weather=None, line='17'):\n",
    "    # line is not implemented by now\n",
    "    start_end = str(start) + '_' + str(end)\n",
    "    if weather == None:\n",
    "        DF_queried = DF_filtered[DF_filtered.eval(\"STARTEND == '{}' and PERIOD == '{}' and WEEK_DAY == {}\".format(start_end,period,dow))]\n",
    "    else:\n",
    "        DF_queried = DF_filtered[DF_filtered.eval(\"STARTEND == '{}' and PERIOD == '{}' and WEEK_DAY == {} and condition == '{}'\".format(start_end,period,dow,weather))]\n",
    "\n",
    "    return DF_queried[\"DISTANCE\"].mean() / DF_queried[\"VELOCITY\"].mean() + DF_queried[\"DWELLTIME\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:08:37.582970Z",
     "start_time": "2020-07-28T05:08:37.570007Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(start=1310, end=1311, dow=0, period = '12:00:00', weather=None, line='17'):\n",
    "    route_test2 = [1380,1381,1406,1407,1409,3353,3354,3355,3356,1400,1391,3357,3358,2449,2450,2451,2434,2435,2436,2437,1117,1118,1119,1120,1299,1300,1301,\\\n",
    "    1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1055,2868,2892,2893,2894,2895,3012,861,862,863,864,865,866,2052,2082,2083,\\\n",
    "    2009,2010,462,464,465,466,467,468,3032,3033,3085]\n",
    "    route_test = [1380,1381,1406,1407,1409,3353,3354,3355,3356,1400,1391,3357,3358,2449,2450,2451,2434,2435,2436,2437,1117,1118,1119,1120,1299,1300,1301,1302,\\\n",
    "    1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1055,2868,2892,2893,2894,2895,3012,861,862,863,864,865,866,2052,765,2007,2008,2009,\\\n",
    "    2010,462,464,465,466,467,468,3032,3033,3085]\n",
    "    results = [0,]\n",
    "    sub_route = sub_route = route_test[route_test.index(start):route_test.index(end)+1]\n",
    "    # TODO: group the time to the period\n",
    "    # TODO: accumulate the time in for loop of each search\n",
    "    for i in range(0,len(sub_route)-1):\n",
    "        if weather != None:\n",
    "            results.append(predict_every_two(sub_route[i],sub_route[i+1],dow,period,weather))\n",
    "        else:\n",
    "            results.append(predict_every_two(sub_route[i],sub_route[i+1],dow,period))\n",
    "    result_df = pd.DataFrame(np.cumsum(results), sub_route, columns=[\"Time cumsum\"])\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:18:12.831046Z",
     "start_time": "2020-07-28T05:18:12.790093Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_every_two(1055, 2868, 0, '14:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:19:02.756505Z",
     "start_time": "2020-07-28T05:19:02.000285Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = predict(1055, 765, 0, '14:00:00')\n",
    "t = predict(1055, 765, 1, '15:00:00')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "H1_dataanalysis",
   "language": "python",
   "name": "h1_dataanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
